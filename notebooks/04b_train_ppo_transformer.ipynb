{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e5f4fbf",
   "metadata": {},
   "source": [
    "# 04b — Train PPO with Transformer extractor (SB3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e93b2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trainer] cfg: TrainConfig(symbol='BTC/USDT', timeframe='1d', start='2021-01-01', end='2023-01-01', window=64, total_timesteps=100000, save_path=None, seed=3991316075, tb=False, n_steps=None, batch_size=None, log_interval=None, policy='MlpPolicy', policy_kwargs={'features_extractor_class': <class 'packages.rl.policies.transformer_extractor.TransformerFeatureExtractor'>, 'features_extractor_kwargs': {'d_model': 32, 'nhead': 4, 'num_layers': 1, 'out_dim': 64}, 'net_arch': [64, 64]}, env_class=<class 'packages.env.trading_env_windowed.WindowedSingleAssetEnv'>, env_kwargs={'window': 64}, use_wandb=False, wandb_project='rl-bybit-ppo', wandb_run_name='ppo-transformer-BTCUSDT-1d')\n",
      "[trainer] rows_raw=548  range=(2021-07-01 00:00:00+00:00 .. 2023-01-01 00:00:00+00:00)\n",
      "[trainer] rows_after_features=548  max_env_steps=547  requested=100000  effective=547\n",
      "/Users/andrewgrit/code/quant/rl-bybit-ppo/.venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/vec_monitor.py:44: UserWarning: The environment is already wrapped with a `Monitor` wrapperbut you are wrapping it with a `VecMonitor` wrapper, the `Monitor` statistics will beoverwritten by the `VecMonitor` ones.\n",
      "  warnings.warn(\n",
      "[trainer] auto params: n_steps=91, batch_size=64, log_interval=1, iters≈6\n",
      "Using cpu device\n",
      "/Users/andrewgrit/code/quant/rl-bybit-ppo/.venv/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 91`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 27\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=91 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[trainer] training for 547 timesteps\n",
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 739 |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 0   |\n",
      "|    total_timesteps | 91  |\n",
      "----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 182         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010753645 |\n",
      "|    clip_fraction        | 0.0353      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.0222      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.979       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 3.12        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 273          |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010973599 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0292       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00127     |\n",
      "|    value_loss           | 0.318        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 364         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004707981 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.737       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0213      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00658    |\n",
      "|    value_loss           | 0.0839      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 70          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 455         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001748442 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.179      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00342    |\n",
      "|    value_loss           | 29.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 484         |\n",
      "|    ep_rew_mean          | -13.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 68          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 546         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020843767 |\n",
      "|    clip_fraction        | 0.0721      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -0.511      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00776    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 0.0203      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 484          |\n",
      "|    ep_rew_mean          | -13.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 68           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 637          |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008657224 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.0276       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.25         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | 0.000777     |\n",
      "|    value_loss           | 2.74         |\n",
      "------------------------------------------\n",
      "[trainer] Saved model to models/ppo-BTCUSDT-1d.zip\n"
     ]
    }
   ],
   "source": [
    "!python -m packages.rl.train_ppo_transformer \\\n",
    "    --symbol BTC/USDT \\\n",
    "    --timeframe 1d \\\n",
    "    --start 2021-01-01 \\\n",
    "    --end 2023-01-01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ea41b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/andrewgrit/.pyenv/versions/3.10.18/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/andrewgrit/.pyenv/versions/3.10.18/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/andrewgrit/code/quant/rl-bybit-ppo/packages/rl/backtest_ppo.py\", line 65, in <module>\n",
      "    main()\n",
      "  File \"/Users/andrewgrit/code/quant/rl-bybit-ppo/packages/rl/backtest_ppo.py\", line 58, in main\n",
      "    results = evaluate_model(model, df, args.window)\n",
      "  File \"/Users/andrewgrit/code/quant/rl-bybit-ppo/packages/rl/backtest_ppo.py\", line 33, in evaluate_model\n",
      "    action, _ = model.predict(obs, deterministic=True)\n",
      "  File \"/Users/andrewgrit/code/quant/rl-bybit-ppo/.venv/lib/python3.10/site-packages/stable_baselines3/common/base_class.py\", line 556, in predict\n",
      "    return self.policy.predict(observation, state, episode_start, deterministic)\n",
      "  File \"/Users/andrewgrit/code/quant/rl-bybit-ppo/.venv/lib/python3.10/site-packages/stable_baselines3/common/policies.py\", line 365, in predict\n",
      "    obs_tensor, vectorized_env = self.obs_to_tensor(observation)\n",
      "  File \"/Users/andrewgrit/code/quant/rl-bybit-ppo/.venv/lib/python3.10/site-packages/stable_baselines3/common/policies.py\", line 272, in obs_to_tensor\n",
      "    vectorized_env = is_vectorized_observation(observation, self.observation_space)\n",
      "  File \"/Users/andrewgrit/code/quant/rl-bybit-ppo/.venv/lib/python3.10/site-packages/stable_baselines3/common/utils.py\", line 401, in is_vectorized_observation\n",
      "    return is_vec_obs_func(observation, observation_space)  # type: ignore[operator]\n",
      "  File \"/Users/andrewgrit/code/quant/rl-bybit-ppo/.venv/lib/python3.10/site-packages/stable_baselines3/common/utils.py\", line 268, in is_vectorized_box_observation\n",
      "    raise ValueError(\n",
      "ValueError: Error: Unexpected observation shape (3,) for Box environment, please use (64, 3) or (n_env, 64, 3) for the observation shape.\n"
     ]
    }
   ],
   "source": [
    "!python -m packages.rl.backtest_ppo \\\n",
    "    --symbol BTC/USDT \\\n",
    "    --timeframe 1d \\\n",
    "    --start 2023-01-01 \\\n",
    "    --end 2024-01-01 \\\n",
    "    --model_path models/ppo-BTCUSDT-1d.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4420b24a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
